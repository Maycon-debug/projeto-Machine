{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Etapa 4: Otimiza√ß√£o e Tuning de Hiperpar√¢metros\n",
        "\n",
        "## Objetivos\n",
        "Otimizar o melhor modelo da Etapa 3 atrav√©s de tuning de hiperpar√¢metros, evitar overfitting, avaliar no conjunto de teste e salvar o modelo final otimizado.\n",
        "\n",
        "**Vari√°vel Alvo**: `final_grade` (Nota Final)\n",
        "\n",
        "**Lembre-se**: \n",
        "- Usar apenas treino e valida√ß√£o para tuning\n",
        "- Avaliar no conjunto de teste APENAS UMA VEZ\n",
        "- Comparar modelo antes vs depois da otimiza√ß√£o\n",
        "- Salvar modelo final para produ√ß√£o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# Configura√ß√£o para exibir gr√°ficos inline no Jupyter Notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Configura√ß√µes de visualiza√ß√£o\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except:\n",
        "    plt.style.use('seaborn-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√£o para exibir todas as colunas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "# Configura√ß√£o adicional para garantir que gr√°ficos apare√ßam\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "print(f\"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Recapitula√ß√£o dos Resultados da Etapa 3\n",
        "\n",
        "Carregar e revisar os resultados do modelo baseline da Etapa 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dados processados da Etapa 2\n",
        "df = pd.read_csv('../../data/processed/students_clean.csv')\n",
        "\n",
        "print(\"Dataset processado carregado com sucesso!\")\n",
        "print(f\"\\nFormato: {df.shape}\")\n",
        "\n",
        "# Separar features (X) e vari√°vel alvo (y)\n",
        "target = 'final_grade'\n",
        "features_to_remove = ['student_id', target]\n",
        "\n",
        "X = df.drop(columns=features_to_remove, errors='ignore')\n",
        "y = df[target]\n",
        "\n",
        "print(f\"\\nFeatures (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "\n",
        "# Carregar modelo baseline da Etapa 3\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Carregando modelo baseline da Etapa 3...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    modelo_baseline = joblib.load('../../models/modelo_baseline.pkl')\n",
        "    print(\"‚úÖ Modelo baseline carregado com sucesso!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è Modelo baseline n√£o encontrado. Ser√° treinado novamente.\")\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    modelo_baseline = LinearRegression()\n",
        "    \n",
        "    # Dividir dados para treinar baseline\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
        "    )\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.25, random_state=42, shuffle=True\n",
        "    )\n",
        "    \n",
        "    modelo_baseline.fit(X_train, y_train)\n",
        "    print(\"‚úÖ Modelo baseline treinado!\")\n",
        "\n",
        "# Dividir dados em treino, valida√ß√£o e teste (mesma divis√£o da Etapa 3)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"\\nDivis√£o dos Dados:\")\n",
        "print(f\"Treino:      {X_train.shape[0]} amostras ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
        "print(f\"Valida√ß√£o:   {X_val.shape[0]} amostras ({X_val.shape[0]/len(df)*100:.1f}%)\")\n",
        "print(f\"Teste:       {X_test.shape[0]} amostras ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
        "print(f\"\\n‚ö†Ô∏è IMPORTANTE: Dados de teste ser√£o usados APENAS UMA VEZ no final!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avaliar modelo baseline para compara√ß√£o futura\n",
        "print(\"=\"*60)\n",
        "print(\"AVALIA√á√ÉO DO MODELO BASELINE (Etapa 3)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Predi√ß√µes do baseline\n",
        "y_train_pred_baseline = modelo_baseline.predict(X_train)\n",
        "y_val_pred_baseline = modelo_baseline.predict(X_val)\n",
        "\n",
        "# M√©tricas do baseline\n",
        "mse_train_baseline = mean_squared_error(y_train, y_train_pred_baseline)\n",
        "rmse_train_baseline = np.sqrt(mse_train_baseline)\n",
        "mae_train_baseline = mean_absolute_error(y_train, y_train_pred_baseline)\n",
        "r2_train_baseline = r2_score(y_train, y_train_pred_baseline)\n",
        "\n",
        "mse_val_baseline = mean_squared_error(y_val, y_val_pred_baseline)\n",
        "rmse_val_baseline = np.sqrt(mse_val_baseline)\n",
        "mae_val_baseline = mean_absolute_error(y_val, y_val_pred_baseline)\n",
        "r2_val_baseline = r2_score(y_val, y_val_pred_baseline)\n",
        "\n",
        "# Criar DataFrame com resultados do baseline\n",
        "resultados_baseline = pd.DataFrame({\n",
        "    'M√©trica': ['MSE', 'RMSE', 'MAE', 'R¬≤'],\n",
        "    'Treino': [mse_train_baseline, rmse_train_baseline, mae_train_baseline, r2_train_baseline],\n",
        "    'Valida√ß√£o': [mse_val_baseline, rmse_val_baseline, mae_val_baseline, r2_val_baseline]\n",
        "})\n",
        "\n",
        "print(\"\\nResultados do Modelo Baseline (Regress√£o Linear):\")\n",
        "print(resultados_baseline.to_string(index=False))\n",
        "\n",
        "print(f\"\\nüìä Resumo:\")\n",
        "print(f\"   R¬≤ Valida√ß√£o: {r2_val_baseline:.4f} ({r2_val_baseline*100:.2f}%)\")\n",
        "print(f\"   RMSE Valida√ß√£o: {rmse_val_baseline:.4f} pontos\")\n",
        "print(f\"   MAE Valida√ß√£o: {mae_val_baseline:.4f} pontos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sele√ß√£o do Modelo para Otimiza√ß√£o\n",
        "\n",
        "Escolher o modelo que ser√° otimizado. Como o baseline foi Regress√£o Linear, vamos otimizar modelos de regress√£o regularizada (Ridge, Lasso, ElasticNet) que s√£o varia√ß√µes da Regress√£o Linear com regulariza√ß√£o para evitar overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Escolher modelo para otimiza√ß√£o\n",
        "# Vamos usar ElasticNet que combina Ridge e Lasso\n",
        "# ElasticNet tem dois hiperpar√¢metros principais: alpha e l1_ratio\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SELE√á√ÉO DO MODELO PARA OTIMIZA√á√ÉO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nModelo escolhido: ElasticNet\")\n",
        "print(\"\\nJustificativa:\")\n",
        "print(\"  - ElasticNet combina regulariza√ß√£o L1 (Lasso) e L2 (Ridge)\")\n",
        "print(\"  - Permite sele√ß√£o de features (L1) e agrupamento de features correlacionadas (L2)\")\n",
        "print(\"  - Mais flex√≠vel que Ridge ou Lasso isolados\")\n",
        "print(\"  - Hiperpar√¢metros: alpha (for√ßa da regulariza√ß√£o) e l1_ratio (propor√ß√£o L1 vs L2)\")\n",
        "\n",
        "# Criar modelo base\n",
        "modelo_base = ElasticNet(random_state=42, max_iter=10000)\n",
        "\n",
        "print(f\"\\n‚úÖ Modelo base criado: {type(modelo_base).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Grid Search ou Random Search\n",
        "\n",
        "Escolher uma t√©cnica de otimiza√ß√£o de hiperpar√¢metros. Vamos implementar ambas as op√ß√µes, mas usar Random Search por ser mais eficiente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Definir grid de hiperpar√¢metros para ElasticNet\n",
        "print(\"=\"*60)\n",
        "print(\"DEFINI√á√ÉO DO GRID DE HIPERPAR√ÇMETROS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Hiperpar√¢metros para ElasticNet:\n",
        "# - alpha: for√ßa da regulariza√ß√£o (valores maiores = mais regulariza√ß√£o)\n",
        "# - l1_ratio: propor√ß√£o de L1 (Lasso) vs L2 (Ridge)\n",
        "#   - l1_ratio = 0: apenas Ridge (L2)\n",
        "#   - l1_ratio = 1: apenas Lasso (L1)\n",
        "#   - 0 < l1_ratio < 1: combina√ß√£o (ElasticNet)\n",
        "\n",
        "# Para Random Search, definimos distribui√ß√µes\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Distribui√ß√£o para alpha (valores entre 0.01 e 100)\n",
        "param_distributions = {\n",
        "    'alpha': uniform(loc=0.01, scale=10),  # uniforme entre 0.01 e 10.01\n",
        "    'l1_ratio': uniform(loc=0, scale=1)    # uniforme entre 0 e 1\n",
        "}\n",
        "\n",
        "print(\"\\nHiperpar√¢metros para otimiza√ß√£o (Random Search):\")\n",
        "print(\"  alpha: distribui√ß√£o uniforme entre 0.01 e 10.01\")\n",
        "print(\"  l1_ratio: distribui√ß√£o uniforme entre 0 e 1\")\n",
        "print(\"\\nN√∫mero de itera√ß√µes: 50 (pode ser aumentado para melhor resultado)\")\n",
        "\n",
        "# Para Grid Search (op√ß√£o alternativa - comentado por ser mais lento)\n",
        "# param_grid = {\n",
        "#     'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "#     'l1_ratio': [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "# }\n",
        "# print(f\"\\nGrid Search teria {len(param_grid['alpha']) * len(param_grid['l1_ratio'])} combina√ß√µes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.2 Executar Random Search com Cross-Validation\n",
        "print(\"=\"*60)\n",
        "print(\"EXECUTANDO RANDOM SEARCH COM CROSS-VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n‚è≥ Isso pode levar alguns minutos...\")\n",
        "print(\"   Usando 5-fold cross-validation para cada combina√ß√£o de hiperpar√¢metros\")\n",
        "\n",
        "# Combinar treino e valida√ß√£o para ter mais dados no tuning\n",
        "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
        "y_train_val = pd.concat([y_train, y_val], axis=0)\n",
        "\n",
        "print(f\"\\nDados combinados para tuning: {X_train_val.shape[0]} amostras\")\n",
        "\n",
        "# Criar RandomizedSearchCV\n",
        "# n_iter: n√∫mero de combina√ß√µes aleat√≥rias a testar\n",
        "# cv: n√∫mero de folds na cross-validation\n",
        "# scoring: m√©trica para otimizar (neg_mean_squared_error = menor MSE)\n",
        "# n_jobs: usar todos os cores dispon√≠veis (-1)\n",
        "# random_state: para reprodutibilidade\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=modelo_base,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=50,  # Testar 50 combina√ß√µes aleat√≥rias\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    scoring='neg_mean_squared_error',  # Queremos minimizar MSE\n",
        "    n_jobs=-1,  # Usar todos os cores\n",
        "    random_state=42,\n",
        "    verbose=1  # Mostrar progresso\n",
        ")\n",
        "\n",
        "# Executar busca\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "random_search.fit(X_train_val, y_train_val)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Random Search conclu√≠do em {elapsed_time:.2f} segundos ({elapsed_time/60:.2f} minutos)\")\n",
        "print(f\"\\nMelhores hiperpar√¢metros encontrados:\")\n",
        "print(f\"  alpha: {random_search.best_params_['alpha']:.4f}\")\n",
        "print(f\"  l1_ratio: {random_search.best_params_['l1_ratio']:.4f}\")\n",
        "print(f\"\\nMelhor score (neg MSE): {random_search.best_score_:.4f}\")\n",
        "print(f\"Melhor RMSE (CV): {np.sqrt(-random_search.best_score_):.4f} pontos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. An√°lise dos Melhores Hiperpar√¢metros\n",
        "\n",
        "Analisar os resultados do Random Search e entender quais hiperpar√¢metros funcionaram melhor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Converter resultados do Random Search em DataFrame\n",
        "print(\"=\"*60)\n",
        "print(\"AN√ÅLISE DOS RESULTADOS DO RANDOM SEARCH\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Converter cv_results_ em DataFrame\n",
        "results_df = pd.DataFrame(random_search.cv_results_)\n",
        "\n",
        "# Calcular RMSE a partir do neg_mean_squared_error\n",
        "results_df['RMSE'] = np.sqrt(-results_df['mean_test_score'])\n",
        "results_df['RMSE_std'] = np.sqrt(results_df['std_test_score'])\n",
        "\n",
        "# Selecionar colunas relevantes\n",
        "cols_to_show = ['param_alpha', 'param_l1_ratio', 'mean_test_score', 'RMSE', 'RMSE_std', 'rank_test_score']\n",
        "results_analysis = results_df[cols_to_show].copy()\n",
        "\n",
        "# Renomear colunas para melhor visualiza√ß√£o\n",
        "results_analysis.columns = ['Alpha', 'L1_Ratio', 'Neg_MSE', 'RMSE', 'RMSE_Std', 'Rank']\n",
        "\n",
        "# Ordenar por rank (melhor = 1)\n",
        "results_analysis = results_analysis.sort_values('Rank')\n",
        "\n",
        "print(\"\\nTop 10 Melhores Combina√ß√µes de Hiperpar√¢metros:\")\n",
        "print(\"=\"*60)\n",
        "print(results_analysis.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.2 Visualizar distribui√ß√£o dos resultados\n",
        "print(\"\\nCriando visualiza√ß√µes dos resultados...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Gr√°fico 1: Alpha vs RMSE\n",
        "ax1 = axes[0, 0]\n",
        "scatter1 = ax1.scatter(results_analysis['Alpha'], results_analysis['RMSE'], \n",
        "                       c=results_analysis['L1_Ratio'], cmap='viridis', \n",
        "                       s=50, alpha=0.6, edgecolors='black')\n",
        "ax1.set_xlabel('Alpha (For√ßa da Regulariza√ß√£o)', fontsize=11, fontweight='bold')\n",
        "ax1.set_ylabel('RMSE (Cross-Validation)', fontsize=11, fontweight='bold')\n",
        "ax1.set_title('Alpha vs RMSE\\n(Cor = L1_Ratio)', fontsize=12, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=ax1, label='L1_Ratio')\n",
        "\n",
        "# Gr√°fico 2: L1_Ratio vs RMSE\n",
        "ax2 = axes[0, 1]\n",
        "scatter2 = ax2.scatter(results_analysis['L1_Ratio'], results_analysis['RMSE'],\n",
        "                       c=results_analysis['Alpha'], cmap='plasma',\n",
        "                       s=50, alpha=0.6, edgecolors='black')\n",
        "ax2.set_xlabel('L1_Ratio (Propor√ß√£o Lasso vs Ridge)', fontsize=11, fontweight='bold')\n",
        "ax2.set_ylabel('RMSE (Cross-Validation)', fontsize=11, fontweight='bold')\n",
        "ax2.set_title('L1_Ratio vs RMSE\\n(Cor = Alpha)', fontsize=12, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "plt.colorbar(scatter2, ax=ax2, label='Alpha')\n",
        "\n",
        "# Gr√°fico 3: Distribui√ß√£o do RMSE\n",
        "ax3 = axes[1, 0]\n",
        "ax3.hist(results_analysis['RMSE'], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "ax3.axvline(results_analysis['RMSE'].min(), color='red', linestyle='--', \n",
        "            linewidth=2, label=f'Melhor: {results_analysis[\"RMSE\"].min():.4f}')\n",
        "ax3.axvline(results_analysis['RMSE'].mean(), color='green', linestyle='--',\n",
        "            linewidth=2, label=f'M√©dia: {results_analysis[\"RMSE\"].mean():.4f}')\n",
        "ax3.set_xlabel('RMSE', fontsize=11, fontweight='bold')\n",
        "ax3.set_ylabel('Frequ√™ncia', fontsize=11, fontweight='bold')\n",
        "ax3.set_title('Distribui√ß√£o do RMSE\\n(Todas as Combina√ß√µes Testadas)', fontsize=12, fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Top 10 melhores com barras de erro\n",
        "ax4 = axes[1, 1]\n",
        "top_10 = results_analysis.head(10)\n",
        "x_pos = range(len(top_10))\n",
        "bars = ax4.barh(x_pos, top_10['RMSE'], xerr=top_10['RMSE_Std'], \n",
        "                alpha=0.7, edgecolor='black', color='steelblue')\n",
        "ax4.set_yticks(x_pos)\n",
        "ax4.set_yticklabels([f\"Œ±={row['Alpha']:.3f}\\nl1={row['L1_Ratio']:.3f}\" \n",
        "                     for _, row in top_10.iterrows()], fontsize=9)\n",
        "ax4.set_xlabel('RMSE (Cross-Validation)', fontsize=11, fontweight='bold')\n",
        "ax4.set_ylabel('Combina√ß√£o de Hiperpar√¢metros', fontsize=11, fontweight='bold')\n",
        "ax4.set_title('Top 10 Melhores Combina√ß√µes\\n(com Desvio Padr√£o)', fontsize=12, fontweight='bold')\n",
        "ax4.invert_yaxis()\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualiza√ß√µes criadas!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.3 An√°lise dos melhores hiperpar√¢metros\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INTERPRETA√á√ÉO DOS MELHORES HIPERPAR√ÇMETROS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_alpha = random_search.best_params_['alpha']\n",
        "best_l1_ratio = random_search.best_params_['l1_ratio']\n",
        "\n",
        "print(f\"\\nMelhor Alpha: {best_alpha:.4f}\")\n",
        "if best_alpha < 0.1:\n",
        "    print(\"  ‚Üí Regulariza√ß√£o muito fraca (pr√≥ximo de Regress√£o Linear simples)\")\n",
        "elif best_alpha < 1.0:\n",
        "    print(\"  ‚Üí Regulariza√ß√£o moderada\")\n",
        "elif best_alpha < 10.0:\n",
        "    print(\"  ‚Üí Regulariza√ß√£o forte\")\n",
        "else:\n",
        "    print(\"  ‚Üí Regulariza√ß√£o muito forte\")\n",
        "\n",
        "print(f\"\\nMelhor L1_Ratio: {best_l1_ratio:.4f}\")\n",
        "if best_l1_ratio < 0.2:\n",
        "    print(\"  ‚Üí Predomin√¢ncia de Ridge (L2) - mant√©m todas as features\")\n",
        "elif best_l1_ratio < 0.5:\n",
        "    print(\"  ‚Üí Mais Ridge que Lasso, mas com alguma sele√ß√£o de features\")\n",
        "elif best_l1_ratio < 0.8:\n",
        "    print(\"  ‚Üí Mais Lasso que Ridge - sele√ß√£o de features importante\")\n",
        "else:\n",
        "    print(\"  ‚Üí Predomin√¢ncia de Lasso (L1) - sele√ß√£o forte de features\")\n",
        "\n",
        "print(f\"\\nüí° Conclus√£o:\")\n",
        "print(f\"   O modelo otimizado usa {best_l1_ratio*100:.1f}% de regulariza√ß√£o L1 (Lasso)\")\n",
        "print(f\"   e {(1-best_l1_ratio)*100:.1f}% de regulariza√ß√£o L2 (Ridge)\")\n",
        "print(f\"   com for√ßa de regulariza√ß√£o alpha = {best_alpha:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Treinamento do Modelo Final\n",
        "\n",
        "Treinar o modelo final com os melhores hiperpar√¢metros usando TREINO + VALIDA√á√ÉO combinados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 Treinar modelo final com melhores hiperpar√¢metros\n",
        "print(\"=\"*60)\n",
        "print(\"TREINAMENTO DO MODELO FINAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# O best_estimator_ j√° est√° treinado com os melhores hiperpar√¢metros\n",
        "# Mas vamos treinar novamente com todos os dados de treino+valida√ß√£o\n",
        "# para ter o m√°ximo de dados poss√≠vel\n",
        "\n",
        "print(\"\\nTreinando modelo final com TREINO + VALIDA√á√ÉO combinados...\")\n",
        "print(f\"Total de amostras: {X_train_val.shape[0]}\")\n",
        "\n",
        "# Criar modelo final com melhores hiperpar√¢metros\n",
        "modelo_final = ElasticNet(\n",
        "    alpha=random_search.best_params_['alpha'],\n",
        "    l1_ratio=random_search.best_params_['l1_ratio'],\n",
        "    random_state=42,\n",
        "    max_iter=10000\n",
        ")\n",
        "\n",
        "# Treinar no conjunto completo (treino + valida√ß√£o)\n",
        "modelo_final.fit(X_train_val, y_train_val)\n",
        "\n",
        "print(\"‚úÖ Modelo final treinado com sucesso!\")\n",
        "\n",
        "# Fazer predi√ß√µes para avalia√ß√£o (ainda n√£o usamos teste!)\n",
        "y_train_val_pred = modelo_final.predict(X_train_val)\n",
        "\n",
        "# Calcular m√©tricas no conjunto de treino+valida√ß√£o\n",
        "mse_train_val = mean_squared_error(y_train_val, y_train_val_pred)\n",
        "rmse_train_val = np.sqrt(mse_train_val)\n",
        "mae_train_val = mean_absolute_error(y_train_val, y_train_val_pred)\n",
        "r2_train_val = r2_score(y_train_val, y_train_val_pred)\n",
        "\n",
        "print(f\"\\nM√©tricas no conjunto de Treino+Valida√ß√£o:\")\n",
        "print(f\"  R¬≤:   {r2_train_val:.4f} ({r2_train_val*100:.2f}%)\")\n",
        "print(f\"  RMSE: {rmse_train_val:.4f} pontos\")\n",
        "print(f\"  MAE:  {mae_train_val:.4f} pontos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Avalia√ß√£o no Conjunto de Teste\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANTE**: Esta √© a √öNICA vez que usaremos o conjunto de teste!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1 Carregar dados de teste (guardados desde a Etapa 3)\n",
        "print(\"=\"*60)\n",
        "print(\"AVALIA√á√ÉO FINAL NO CONJUNTO DE TESTE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n‚ö†Ô∏è ATEN√á√ÉO: Esta √© a √öNICA vez que usaremos o conjunto de teste!\")\n",
        "\n",
        "# Carregar dados de teste salvos\n",
        "X_test = pd.read_csv('../../data/processed/X_test.csv')\n",
        "y_test = pd.read_csv('../../data/processed/y_test.csv').squeeze()\n",
        "\n",
        "print(f\"\\nDados de teste carregados:\")\n",
        "print(f\"  X_test: {X_test.shape}\")\n",
        "print(f\"  y_test: {y_test.shape}\")\n",
        "\n",
        "# Fazer predi√ß√µes no conjunto de teste\n",
        "print(\"\\nFazendo predi√ß√µes no conjunto de teste...\")\n",
        "y_test_pred = modelo_final.predict(X_test)\n",
        "\n",
        "# Calcular m√©tricas finais\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"M√âTRICAS FINAIS NO CONJUNTO DE TESTE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nMSE  (Erro Quadr√°tico M√©dio):     {mse_test:.4f}\")\n",
        "print(f\"RMSE (Raiz do Erro Quadr√°tico):    {rmse_test:.4f} pontos\")\n",
        "print(f\"MAE  (Erro Absoluto M√©dio):        {mae_test:.4f} pontos\")\n",
        "print(f\"R¬≤   (Coeficiente de Determina√ß√£o): {r2_test:.4f} ({r2_test*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nüí° Interpreta√ß√£o:\")\n",
        "print(f\"   O modelo explica {r2_test*100:.2f}% da varia√ß√£o nas notas finais\")\n",
        "print(f\"   Em m√©dia, o modelo erra por {rmse_test:.2f} pontos\")\n",
        "print(f\"   O erro m√©dio absoluto √© de {mae_test:.2f} pontos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compara√ß√£o: Antes vs Depois da Otimiza√ß√£o\n",
        "\n",
        "Comparar o desempenho do modelo baseline (Etapa 3) com o modelo otimizado (Etapa 4).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.1 Avaliar baseline no conjunto de teste para compara√ß√£o justa\n",
        "print(\"=\"*60)\n",
        "print(\"COMPARA√á√ÉO: BASELINE vs MODELO OTIMIZADO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Avaliar baseline no teste (para compara√ß√£o justa)\n",
        "y_test_pred_baseline = modelo_baseline.predict(X_test)\n",
        "\n",
        "mse_test_baseline = mean_squared_error(y_test, y_test_pred_baseline)\n",
        "rmse_test_baseline = np.sqrt(mse_test_baseline)\n",
        "mae_test_baseline = mean_absolute_error(y_test, y_test_pred_baseline)\n",
        "r2_test_baseline = r2_score(y_test, y_test_pred_baseline)\n",
        "\n",
        "# Criar tabela comparativa\n",
        "comparacao = pd.DataFrame({\n",
        "    'M√©trica': ['MSE', 'RMSE', 'MAE', 'R¬≤'],\n",
        "    'Baseline (Etapa 3)': [\n",
        "        mse_test_baseline,\n",
        "        rmse_test_baseline,\n",
        "        mae_test_baseline,\n",
        "        r2_test_baseline\n",
        "    ],\n",
        "    'Otimizado (Etapa 4)': [\n",
        "        mse_test,\n",
        "        rmse_test,\n",
        "        mae_test,\n",
        "        r2_test\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Calcular melhoria\n",
        "comparacao['Melhoria'] = comparacao['Baseline (Etapa 3)'] - comparacao['Otimizado (Etapa 4)']\n",
        "comparacao['Melhoria (%)'] = (\n",
        "    (comparacao['Melhoria'] / comparacao['Baseline (Etapa 3)']) * 100\n",
        ").round(2)\n",
        "\n",
        "# Para R¬≤, queremos aumento (n√£o diminui√ß√£o)\n",
        "comparacao.loc[comparacao['M√©trica'] == 'R¬≤', 'Melhoria (%)'] = (\n",
        "    ((comparacao.loc[comparacao['M√©trica'] == 'R¬≤', 'Otimizado (Etapa 4)'].values[0] - \n",
        "      comparacao.loc[comparacao['M√©trica'] == 'R¬≤', 'Baseline (Etapa 3)'].values[0]) / \n",
        "     comparacao.loc[comparacao['M√©trica'] == 'R¬≤', 'Baseline (Etapa 3)'].values[0]) * 100\n",
        ").round(2)\n",
        "\n",
        "print(\"\\nCompara√ß√£o no Conjunto de Teste:\")\n",
        "print(\"=\"*60)\n",
        "print(comparacao.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.2 Visualizar compara√ß√£o\n",
        "print(\"\\nCriando gr√°ficos de compara√ß√£o...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Compara√ß√£o de m√©tricas\n",
        "ax1 = axes[0]\n",
        "x = np.arange(len(comparacao['M√©trica']))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax1.bar(x - width/2, comparacao['Baseline (Etapa 3)'], width, \n",
        "                label='Baseline', alpha=0.8, color='lightcoral', edgecolor='black')\n",
        "bars2 = ax1.bar(x + width/2, comparacao['Otimizado (Etapa 4)'], width,\n",
        "                label='Otimizado', alpha=0.8, color='steelblue', edgecolor='black')\n",
        "\n",
        "ax1.set_xlabel('M√©trica', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Valor', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Compara√ß√£o: Baseline vs Modelo Otimizado\\n(Conjunto de Teste)', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(comparacao['M√©trica'])\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Gr√°fico 2: Melhoria percentual\n",
        "ax2 = axes[1]\n",
        "colors = ['green' if x > 0 else 'red' for x in comparacao['Melhoria (%)']]\n",
        "bars = ax2.barh(comparacao['M√©trica'], comparacao['Melhoria (%)'], \n",
        "                color=colors, alpha=0.7, edgecolor='black')\n",
        "ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
        "ax2.set_xlabel('Melhoria (%)', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('M√©trica', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Melhoria Percentual do Modelo Otimizado\\n(Verde = Melhorou | Vermelho = Piorou)', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    label_x = width if width > 0 else width - 0.5\n",
        "    ax2.text(label_x, bar.get_y() + bar.get_height()/2,\n",
        "            f' {width:.2f}%', ha='left' if width > 0 else 'right', \n",
        "            va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Gr√°ficos de compara√ß√£o criados!\")\n",
        "\n",
        "# Resumo da melhoria\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESUMO DA MELHORIA\")\n",
        "print(\"=\"*60)\n",
        "melhoria_r2 = comparacao.loc[comparacao['M√©trica'] == 'R¬≤', 'Melhoria (%)'].values[0]\n",
        "melhoria_rmse = comparacao.loc[comparacao['M√©trica'] == 'RMSE', 'Melhoria (%)'].values[0]\n",
        "\n",
        "if melhoria_r2 > 0:\n",
        "    print(f\"\\n‚úÖ R¬≤ melhorou em {melhoria_r2:.2f}%\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è R¬≤ diminuiu em {abs(melhoria_r2):.2f}%\")\n",
        "\n",
        "if melhoria_rmse < 0:  # RMSE menor √© melhor\n",
        "    print(f\"‚úÖ RMSE melhorou em {abs(melhoria_rmse):.2f}% (diminuiu)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è RMSE piorou em {melhoria_rmse:.2f}% (aumentou)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. An√°lise de Erros Detalhada\n",
        "\n",
        "Realizar an√°lise detalhada dos erros do modelo final no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8.1 Scatter Plot: Predito vs Real\n",
        "print(\"=\"*60)\n",
        "print(\"AN√ÅLISE DE ERROS DETALHADA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# Gr√°fico 1: Predito vs Real\n",
        "ax1 = axes[0]\n",
        "ax1.scatter(y_test, y_test_pred, alpha=0.5, s=30, color='steelblue', edgecolors='black', linewidth=0.5)\n",
        "\n",
        "# Linha perfeita (y = x)\n",
        "min_val = min(y_test.min(), y_test_pred.min())\n",
        "max_val = max(y_test.max(), y_test_pred.max())\n",
        "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Linha Perfeita (Predi√ß√£o = Real)')\n",
        "\n",
        "ax1.set_xlabel('Valores Reais (Nota Final)', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Predi√ß√µes do Modelo (Nota Final)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Scatter Plot: Predi√ß√µes vs Valores Reais\\n(Conjunto de Teste)', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax1.legend(fontsize=10, loc='lower right')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Adicionar R¬≤ e RMSE no gr√°fico\n",
        "textstr = f'R¬≤ = {r2_test:.4f} ({r2_test*100:.2f}%)\\nRMSE = {rmse_test:.2f} pontos'\n",
        "ax1.text(0.05, 0.95, textstr, transform=ax1.transAxes,\n",
        "         fontsize=11, verticalalignment='top', \n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
        "\n",
        "# Gr√°fico 2: Res√≠duos vs Predi√ß√µes\n",
        "residuos = y_test - y_test_pred\n",
        "ax2 = axes[1]\n",
        "ax2.scatter(y_test_pred, residuos, alpha=0.5, s=30, color='steelblue', edgecolors='black', linewidth=0.5)\n",
        "ax2.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero (Ideal)')\n",
        "ax2.set_xlabel('Predi√ß√µes do Modelo (Nota Final)', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Res√≠duos (Valor Real - Predi√ß√£o)', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Res√≠duos vs Predi√ß√µes\\n(Verificar Padr√µes e Homocedasticidade)', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Gr√°ficos de an√°lise de erros criados!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8.2 Distribui√ß√£o dos Res√≠duos\n",
        "print(\"\\nCriando gr√°ficos de distribui√ß√£o dos res√≠duos...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Subplot 1: Histograma dos res√≠duos\n",
        "ax1 = axes[0]\n",
        "ax1.hist(residuos, bins=30, edgecolor='black', alpha=0.7, color='skyblue', label='Distribui√ß√£o dos Res√≠duos')\n",
        "ax1.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero (Ideal)')\n",
        "ax1.axvline(x=residuos.mean(), color='green', linestyle='--', linewidth=2, \n",
        "            label=f'M√©dia: {residuos.mean():.2f}')\n",
        "ax1.set_xlabel('Res√≠duos (Valor Real - Predi√ß√£o)', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Frequ√™ncia (Quantidade de Amostras)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Histograma: Distribui√ß√£o dos Res√≠duos\\n(Conjunto de Teste)', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Adicionar estat√≠sticas\n",
        "textstr = f'M√©dia: {residuos.mean():.4f}\\nDesvio Padr√£o: {residuos.std():.4f}\\nM√≠nimo: {residuos.min():.2f}\\nM√°ximo: {residuos.max():.2f}'\n",
        "ax1.text(0.98, 0.98, textstr, transform=ax1.transAxes,\n",
        "         fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
        "\n",
        "# Subplot 2: Q-Q Plot (verificar normalidade dos res√≠duos)\n",
        "from scipy import stats\n",
        "ax2 = axes[1]\n",
        "stats.probplot(residuos, dist=\"norm\", plot=ax2)\n",
        "ax2.set_title('Q-Q Plot: Normalidade dos Res√≠duos\\n(Conjunto de Teste)', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Estat√≠sticas dos res√≠duos\n",
        "print(\"\\nEstat√≠sticas dos Res√≠duos:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  M√©dia: {residuos.mean():.4f} (ideal: pr√≥xima de 0)\")\n",
        "print(f\"  Desvio Padr√£o: {residuos.std():.4f}\")\n",
        "print(f\"  M√≠nimo: {residuos.min():.4f}\")\n",
        "print(f\"  M√°ximo: {residuos.max():.4f}\")\n",
        "print(f\"  Mediana: {residuos.median():.4f}\")\n",
        "\n",
        "print(\"\\nüí° Interpreta√ß√£o:\")\n",
        "if abs(residuos.mean()) < 0.5:\n",
        "    print(\"  ‚úÖ M√©dia pr√≥xima de zero: modelo n√£o tem vi√©s sistem√°tico\")\n",
        "else:\n",
        "    print(\"  ‚ö†Ô∏è M√©dia distante de zero: modelo pode ter vi√©s\")\n",
        "\n",
        "if abs(residuos.skew()) < 0.5:\n",
        "    print(\"  ‚úÖ Distribui√ß√£o aproximadamente sim√©trica\")\n",
        "else:\n",
        "    print(f\"  ‚ö†Ô∏è Distribui√ß√£o assim√©trica (skewness: {residuos.skew():.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8.3 An√°lise de Casos Extremos (Piores Predi√ß√µes)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"AN√ÅLISE DE CASOS EXTREMOS - PIORES PREDI√á√ïES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calcular erro absoluto\n",
        "erro_absoluto = np.abs(residuos)\n",
        "\n",
        "# Encontrar top 10 piores predi√ß√µes\n",
        "top_10_erros = erro_absoluto.nlargest(10)\n",
        "\n",
        "# Criar DataFrame com informa√ß√µes dos piores casos\n",
        "casos_extremos = pd.DataFrame({\n",
        "    '√çndice': top_10_erros.index,\n",
        "    'Valor Real': y_test.iloc[top_10_erros.index],\n",
        "    'Predi√ß√£o': y_test_pred[top_10_erros.index],\n",
        "    'Erro Absoluto': top_10_erros.values,\n",
        "    'Res√≠duo': residuos.iloc[top_10_erros.index]\n",
        "})\n",
        "\n",
        "# Ordenar por erro absoluto (maior primeiro)\n",
        "casos_extremos = casos_extremos.sort_values('Erro Absoluto', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Piores Predi√ß√µes (Maiores Erros):\")\n",
        "print(\"=\"*60)\n",
        "print(casos_extremos.to_string(index=False))\n",
        "\n",
        "# An√°lise\n",
        "print(\"\\nüí° An√°lise dos Casos Extremos:\")\n",
        "print(f\"   Maior erro: {casos_extremos['Erro Absoluto'].max():.2f} pontos\")\n",
        "print(f\"   Erro m√©dio nos top 10: {casos_extremos['Erro Absoluto'].mean():.2f} pontos\")\n",
        "print(f\"   Erro m√©dio geral: {erro_absoluto.mean():.2f} pontos\")\n",
        "\n",
        "# Verificar se h√° padr√£o (subestima√ß√£o ou superestima√ß√£o)\n",
        "subestimados = (casos_extremos['Res√≠duo'] > 0).sum()\n",
        "superestimados = (casos_extremos['Res√≠duo'] < 0).sum()\n",
        "\n",
        "print(f\"\\n   Nos piores casos:\")\n",
        "print(f\"   - Subestimados (predi√ß√£o < real): {subestimados} casos\")\n",
        "print(f\"   - Superestimados (predi√ß√£o > real): {superestimados} casos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Salvamento do Modelo Final\n",
        "\n",
        "Salvar o modelo otimizado e treinado para uso em produ√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9.1 Salvar o modelo final otimizado\n",
        "print(\"=\"*60)\n",
        "print(\"SALVAMENTO DO MODELO FINAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Criar diret√≥rio models se n√£o existir\n",
        "os.makedirs('../../models', exist_ok=True)\n",
        "\n",
        "# Salvar modelo final\n",
        "model_path = '../../models/modelo_final.pkl'\n",
        "joblib.dump(modelo_final, model_path)\n",
        "\n",
        "print(f\"‚úÖ Modelo final salvo em: {model_path}\")\n",
        "print(f\"\\nInforma√ß√µes do Modelo:\")\n",
        "print(f\"   Tipo: ElasticNet\")\n",
        "print(f\"   Alpha: {random_search.best_params_['alpha']:.4f}\")\n",
        "print(f\"   L1_Ratio: {random_search.best_params_['l1_ratio']:.4f}\")\n",
        "print(f\"   Features: {X_train_val.shape[1]}\")\n",
        "print(f\"\\nM√©tricas no Conjunto de Teste:\")\n",
        "print(f\"   R¬≤:   {r2_test:.4f} ({r2_test*100:.2f}%)\")\n",
        "print(f\"   RMSE: {rmse_test:.4f} pontos\")\n",
        "print(f\"   MAE:  {mae_test:.4f} pontos\")\n",
        "\n",
        "# Verificar tamanho do arquivo\n",
        "if os.path.exists(model_path):\n",
        "    file_size = os.path.getsize(model_path) / 1024  # KB\n",
        "    print(f\"\\n   Tamanho do arquivo: {file_size:.2f} KB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9.2 Testar se o modelo carregado funciona corretamente\n",
        "print(\"\\nTestando modelo carregado...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Carregar modelo\n",
        "modelo_carregado = joblib.load(model_path)\n",
        "\n",
        "# Fazer predi√ß√£o de teste\n",
        "predicao_teste = modelo_carregado.predict(X_test.iloc[:5])\n",
        "\n",
        "print(\"‚úÖ Modelo carregado com sucesso!\")\n",
        "print(f\"\\nTeste de predi√ß√£o (primeiras 5 amostras):\")\n",
        "print(f\"  Valores reais:    {y_test.iloc[:5].values}\")\n",
        "print(f\"  Predi√ß√µes:        {predicao_teste}\")\n",
        "print(f\"  Erros:            {y_test.iloc[:5].values - predicao_teste}\")\n",
        "\n",
        "# Verificar se as predi√ß√µes s√£o iguais\n",
        "predicoes_originais = modelo_final.predict(X_test.iloc[:5])\n",
        "if np.allclose(predicao_teste, predicoes_originais):\n",
        "    print(\"\\n‚úÖ Modelo carregado funciona corretamente!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Diferen√ßas detectadas entre modelo original e carregado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Conclus√µes Finais\n",
        "\n",
        "Resumo final dos resultados da otimiza√ß√£o e pr√≥ximos passos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumo final\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO FINAL - ETAPA 4: OTIMIZA√á√ÉO E TUNING DE HIPERPAR√ÇMETROS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìä Modelo Otimizado:\")\n",
        "print(f\"   Tipo: ElasticNet\")\n",
        "print(f\"   Alpha: {random_search.best_params_['alpha']:.4f}\")\n",
        "print(f\"   L1_Ratio: {random_search.best_params_['l1_ratio']:.4f}\")\n",
        "\n",
        "print(f\"\\nüìà M√©tricas de Desempenho (Conjunto de Teste):\")\n",
        "print(f\"   R¬≤:   {r2_test:.4f} ({r2_test*100:.2f}%)\")\n",
        "print(f\"   RMSE: {rmse_test:.4f} pontos\")\n",
        "print(f\"   MAE:  {mae_test:.4f} pontos\")\n",
        "\n",
        "print(f\"\\nüîÑ Compara√ß√£o com Baseline:\")\n",
        "melhoria_r2 = comparacao.loc[comparacao['M√©trica'] == 'R¬≤', 'Melhoria (%)'].values[0]\n",
        "melhoria_rmse = comparacao.loc[comparacao['M√©trica'] == 'RMSE', 'Melhoria (%)'].values[0]\n",
        "print(f\"   R¬≤:   {melhoria_r2:+.2f}%\")\n",
        "print(f\"   RMSE: {melhoria_rmse:+.2f}%\")\n",
        "\n",
        "print(f\"\\nüîç An√°lise de Erros:\")\n",
        "print(f\"   M√©dia dos res√≠duos: {residuos.mean():.4f}\")\n",
        "print(f\"   Desvio padr√£o: {residuos.std():.4f}\")\n",
        "print(f\"   Maior erro: {erro_absoluto.max():.2f} pontos\")\n",
        "\n",
        "print(f\"\\nüíæ Arquivos Salvos:\")\n",
        "print(f\"   Modelo final: ../../models/modelo_final.pkl\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ETAPA 4 CONCLU√çDA!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Documenta√ß√£o: Storytelling e Conclus√µes\n",
        "\n",
        "#### Contexto\n",
        "[Descrever o objetivo da otimiza√ß√£o e o que foi feito]\n",
        "\n",
        "#### Metodologia de Otimiza√ß√£o\n",
        "[Explicar por que escolheu Random Search vs Grid Search]\n",
        "[Explicar por que escolheu ElasticNet]\n",
        "[Descrever o processo de cross-validation]\n",
        "\n",
        "#### Resultados da Otimiza√ß√£o\n",
        "[Interpretar os melhores hiperpar√¢metros encontrados]\n",
        "[Explicar o que significam alpha e l1_ratio escolhidos]\n",
        "\n",
        "#### Compara√ß√£o: Antes vs Depois\n",
        "[Analisar se houve melhoria significativa]\n",
        "[Explicar por que melhorou (ou n√£o melhorou)]\n",
        "\n",
        "#### An√°lise de Erros\n",
        "[Interpretar os gr√°ficos de res√≠duos]\n",
        "[Analisar os casos extremos - por que o modelo errou?]\n",
        "[Verificar se h√° padr√µes nos erros]\n",
        "\n",
        "#### Limita√ß√µes do Modelo\n",
        "[Quais s√£o as limita√ß√µes do modelo atual?]\n",
        "[Em que situa√ß√µes o modelo pode falhar?]\n",
        "\n",
        "#### Poss√≠veis Melhorias Futuras\n",
        "[O que poderia ser feito para melhorar ainda mais?]\n",
        "[Quais outras t√©cnicas poderiam ser testadas?]\n",
        "[Feature engineering adicional? Outros algoritmos?]\n",
        "\n",
        "#### Conclus√µes\n",
        "[Resumir o desempenho final do modelo]\n",
        "[O modelo est√° pronto para produ√ß√£o?]\n",
        "[Quais s√£o os pr√≥ximos passos?]\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
